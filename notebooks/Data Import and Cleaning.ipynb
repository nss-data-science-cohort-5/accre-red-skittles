{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ACCRE Project - Data Import and Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.dates import DateFormatter\n",
    "import matplotlib.dates as mdates\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in fullsample.csv as a dataframe\n",
    "jobs = pd.read_csv(\"../data/fullsample-corrected.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Convert BEGIN and END columns to datetime type\n",
    "jobs['BEGIN'] = pd.to_datetime(jobs['BEGIN'], errors='coerce')\n",
    "jobs['END'] = pd.to_datetime(jobs['END'], errors='coerce')\n",
    "\n",
    "# Drop all columns with null type in BEGIN or END columns\n",
    "jobs = jobs.dropna(subset=['BEGIN', 'END'])\n",
    "\n",
    "# Calculate length of jobs and assign in new column JOBLENGTH\n",
    "jobs['JOBLENGTH'] = jobs['END'] - jobs['BEGIN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate total required memory, required memory per core, and total used memory for each job\n",
    "for row_tuple in jobs.itertuples():\n",
    "    memory = row_tuple[5]\n",
    "    memory_int = int(re.findall(r'\\d+', memory)[0]) \n",
    "    used_mem = int(re.findall(r'\\d+', row_tuple[6])[0])\n",
    "    nodes = row_tuple[9] \n",
    "    cpus = row_tuple[10]\n",
    "    total_used_mem = used_mem * nodes\n",
    "    \n",
    "    if 'Mn' in memory:\n",
    "        total_memory = memory_int * nodes\n",
    "        jobs.at[row_tuple[0], 'REQMEMTOT'] = total_memory\n",
    "        if cpus == 0:\n",
    "            jobs.at[row_tuple[0], 'REQMEMPERCORE'] = total_memory\n",
    "        else:\n",
    "            jobs.at[row_tuple[0], 'REQMEMPERCORE'] = total_memory / cpus\n",
    "    elif 'Mc' in memory:\n",
    "        total_memory = memory_int * cpus\n",
    "        jobs.at[row_tuple[0], 'REQMEMTOT'] = total_memory\n",
    "        jobs.at[row_tuple[0], 'REQMEMPERCORE'] = memory_int\n",
    "        \n",
    "    if used_mem == 0:\n",
    "        jobs.at[row_tuple[0], 'USEDMEMTOT'] = 0\n",
    "    else:\n",
    "        jobs.at[row_tuple[0], 'USEDMEMTOT'] = total_used_mem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in ce5 log file\n",
    "ce5 = pd.read_table(\"../data/slurm_wrapper_ce5.log\", \n",
    "                    engine='python',\n",
    "                    sep=\" - \", \n",
    "                    names=['DATE', \n",
    "                           'USER', \n",
    "                           'RETRY',\n",
    "                           'TIMELAPS',\n",
    "                           'RETURNCODE',\n",
    "                           'COMMAND'])\n",
    "\n",
    "# Create new column in ce5 dataframe for which server the data came from\n",
    "ce5['SERVERID'] = 'ce5'\n",
    "\n",
    "# Read in ce6 log file\n",
    "ce6 = pd.read_table(\"../data/slurm_wrapper_ce6.log\", \n",
    "                    engine='python',\n",
    "                    sep=\" - \", \n",
    "                    names=['DATE', \n",
    "                           'USER', \n",
    "                           'RETRY',\n",
    "                           'TIMELAPS',\n",
    "                           'RETURNCODE',\n",
    "                           'COMMAND'])\n",
    "\n",
    "# Create new column in ce6 dataframe for which server the data came from\n",
    "ce6['SERVERID'] = 'ce6'\n",
    "\n",
    "# Combine the two log files into one dataframe\n",
    "logs = pd.concat([ce5, ce6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export cleaned dataframe as a csv\n",
    "jobs.to_csv('../data/fullsample_cleaned.csv', index=False)\n",
    "\n",
    "# Export logs as a csv\n",
    "logs.to_csv('../data/logs.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
